{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm5fqH4YjUVpoOR2S0VEbg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arikalamonisha/finalexam/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies (if needed)\n",
        "!pip install -q seaborn scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, optimizers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load FashionMNIST\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train[..., np.newaxis] / 255.0\n",
        "x_test = x_test[..., np.newaxis] / 255.0\n",
        "\n",
        "# Model creation function\n",
        "def create_model(optimizer='adam', learning_rate=0.001):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D(2,2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    if optimizer == 'adam':\n",
        "        opt = optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Grid search parameters\n",
        "grid = {'batch_size': [64, 128], 'optimizer': ['adam', 'sgd'], 'learning_rate': [0.001, 0.0005]}\n",
        "param_grid = list(ParameterGrid(grid))\n",
        "\n",
        "# Search best model\n",
        "best_val_acc = 0\n",
        "best_model = None\n",
        "best_params = None\n",
        "\n",
        "for params in param_grid:\n",
        "    print(\"Training with:\", params)\n",
        "    # Define fresh callbacks inside loop\n",
        "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, min_lr=1e-5, verbose=0)\n",
        "    early_stop = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "    model = create_model(params['optimizer'], params['learning_rate'])\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        validation_split=0.2,\n",
        "                        epochs=15,\n",
        "                        batch_size=params['batch_size'],\n",
        "                        verbose=0,\n",
        "                        callbacks=[reduce_lr, early_stop])\n",
        "    val_acc = max(history.history['val_accuracy'])\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model = model\n",
        "        best_params = params\n",
        "        best_history = history\n",
        "\n",
        "print(\"Best parameters found:\", best_params)\n",
        "loss, acc = best_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "y_pred = np.argmax(best_model.predict(x_test), axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Loss & Accuracy plots\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(best_history.history['loss'], label='Train Loss')\n",
        "plt.plot(best_history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(best_history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(best_history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# t-SNE Projection\n",
        "features = models.Model(inputs=best_model.input, outputs=best_model.layers[-2].output).predict(x_test[:1000])\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_proj = tsne.fit_transform(features)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=tsne_proj[:,0], y=tsne_proj[:,1], hue=y_test[:1000], palette='tab10', legend='full')\n",
        "plt.title(\"t-SNE Projection of CNN Features\")\n",
        "plt.show()\n",
        "\n",
        "# Visualize First Layer Filters\n",
        "filters, _ = best_model.layers[0].get_weights()\n",
        "plt.figure(figsize=(8, 4))\n",
        "for i in range(6):\n",
        "    plt.subplot(1, 6, i+1)\n",
        "    plt.imshow(filters[:, :, 0, i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"First Layer Filters\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23RdN3eJxnVv",
        "outputId": "f49cab18-bc01-4416-c955-bafd6c994297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training with: {'batch_size': 64, 'learning_rate': 0.001, 'optimizer': 'adam'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    }
  ]
}